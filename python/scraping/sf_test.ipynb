{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "from enum import Enum, unique\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Debug = True   # if debug mode.  Debug = True. if Release mode, Debug = False.\n",
    "G_Chrome_Hide = True\n",
    "G_Debug_Pages = 1\n",
    "G_Debug_Items = 10\n",
    "\n",
    "G_FILE_NAME = 'tianjin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will bid\n",
    "# sourceUrl = (\"https://sf.taobao.com/item_list.htm?spm=a213w.7398504.filter.60.53db26cdCGMLqt&category=50025969\"  \n",
    "#                    \"&auction_source=0&province=%CC%EC%BD%F2&sorder=1&st_param=-1&auction_start_seg=-1\")\n",
    "# #done bid\n",
    "sourceUrl = (\"https://sf.taobao.com/item_list.htm?category=50025969&auction_source=0&province=%CC%EC%BD%F2&sorder=2\"\n",
    "               \"&st_param=-1&auction_start_seg=&auction_start_from=2019-01-01&auction_start_to=2019-07-10&&spm=a213w.3064813.9001.2\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(page_id,item_id,status):\n",
    "    print(\"page id: {0}, item id: {1}, status:{2}\".format(page_id,item_id,status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class Data(Enum):\n",
    "\n",
    "    #release\n",
    "    name = \"name\"\n",
    "    year = \"year\"\n",
    "    month = \"month\"\n",
    "    start = \"start\"\n",
    "    end = \"end\"\n",
    "    times = \"bidNumber\"\n",
    "    title = \"title\"\n",
    "    origin_price = \"originPrice\"\n",
    "    current_price = \"currentPrice\"\n",
    "    discount = \"discount\"\n",
    "    unit = \"unit\"\n",
    "    bid_count = \"bidCount\"\n",
    "    delay_count = \"delayCount\"\n",
    "    apply_count = \"applyCount\"    \n",
    "    area = \"area\"\n",
    "    item_url = \"itemUrl\"\n",
    "    \n",
    "    #debug\n",
    "    areaA = \"areaA\"\n",
    "    areaB = \"areaB\"\n",
    "    bid_id = \"id\"\n",
    "    status = \"status\"\n",
    "    consult_price = \"consultPrice\"\n",
    "    market_price = \"marketPrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManagement:\n",
    "    def __init__(self,file_name):\n",
    "        self.data = {}\n",
    "\n",
    "        self.file_name = file_name\n",
    "    \n",
    "        self.head = []\n",
    "        for data in Data:\n",
    "            self.head.append(data.value)\n",
    "        \n",
    "        self.__open_file()\n",
    "\n",
    "    def __process_attri_name(self,attribute, data):\n",
    "        index = data.find(\"通过\")\n",
    "        data = data[4:index]\n",
    "        self.data[attribute] =  data     \n",
    "            \n",
    "    def __process_attri_area(self,attribute, data):\n",
    "        left = data.find(\"建筑面积\")\n",
    "        if(left != -1):\n",
    "            size = data[(left+4) : (left+22)]\n",
    "            areas = re.findall(r\"\\d+\\.\\d*\",size)\n",
    "            self.data[attribute] = areas[0] if areas else 0\n",
    "        else:\n",
    "            self.data[attribute] = 0\n",
    "        \n",
    "    def __process_attri_date(self,attribute, data):\n",
    "        time1 = int(int(data)/1000 )\n",
    "        self.data[attribute] = str(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time1)))\n",
    "        \n",
    "    def __process_attri_times(self,attribute, data):\n",
    "        keyword_postion = data.find(\"卖\")\n",
    "        if(keyword_postion != -1):\n",
    "            data = data[1:keyword_postion+1]\n",
    "        else:\n",
    "            data = \"no content\"\n",
    "            \n",
    "        self.data[attribute] = data\n",
    "\n",
    "\n",
    "\n",
    "    def __process_attri_common(self,attribute, data):\n",
    "        self.data[attribute] =  data        \n",
    "     \n",
    "    def __process_attri_url(self,attribute, data):\n",
    "        url = \"https:\"+data\n",
    "        self.data[attribute] =  url        \n",
    "\n",
    "    \n",
    "    def __clac_data(self):\n",
    "        # \n",
    "        if (int(self.data[Data.consult_price.value]) > 0):\n",
    "            originPrice = self.data[Data.consult_price.value]\n",
    "        else:\n",
    "            originPrice = self.data[Data.market_price.value]\n",
    "        #\n",
    "        if (int(originPrice)  == 0):\n",
    "            self.data[Data.discount.value] = \"error\"\n",
    "        else:\n",
    "            self.data[Data.discount.value]  = float(\"%.2f\" % float(int(self.data[Data.consult_price.value])/originPrice))\n",
    " \n",
    "       # change unit to from RMB yuan to  RMB Wan\n",
    "        self.data[Data.origin_price.value]  = float(\"%.2f\" % float(int(originPrice)/10000))        \n",
    "        self.data[Data.current_price.value] = float(\"%.2f\" % float(int(self.data[Data.current_price.value])/10000))\n",
    "\n",
    "      # set area\n",
    "        if(float(self.data[Data.areaA.value]) > 0):\n",
    "            self.data[Data.area.value]  = self.data[Data.areaA.value]\n",
    "            self.data[Data.unit.value] = float(\"%.2f\" % float(int(self.data[Data.current_price.value])/float(self.data[\"area\"]) ))\n",
    "        elif(float(self.data[Data.areaB.value]) > 0):\n",
    "            self.data[Data.area.value] = self.data[Data.areaB.value]\n",
    "            self.data[Data.unit.value] = float(\"%.2f\" % float(int(self.data[Data.current_price.value])/float(self.data[\"area\"]) ))\n",
    "        else:\n",
    "            self.data[Data.area.value] = 0\n",
    "            self.data[Data.unit.value] = 0\n",
    "      \n",
    "        ## set year, month\n",
    "        date_start = self.data[Data.start.value]\n",
    "        data_split = date_start.split(\"-\",2)\n",
    "        self.data[Data.year.value] = data_split[0]\n",
    "        self.data[Data.month.value] = data_split[1]\n",
    "\n",
    "    \n",
    "    def set_data(self,attribute, data):\n",
    "        if(attribute == Data.name.value):\n",
    "            self.__process_attri_name(attribute, data)\n",
    "        elif(attribute == Data.areaA.value or attribute == Data.areaB.value):\n",
    "            self.__process_attri_area(attribute, data)\n",
    "        elif(attribute == Data.start.value or attribute == Data.end.value):\n",
    "            self.__process_attri_date(attribute, data)\n",
    "        elif(attribute == Data.times.value):\n",
    "            self.__process_attri_times(attribute, data)\n",
    "        elif(attribute == Data.item_url.value):\n",
    "            self.__process_attri_url(attribute, data)\n",
    "        else:\n",
    "            self.__process_attri_common(attribute,data)    \n",
    "    \n",
    "    \n",
    "    def get_data(self,attribute):\n",
    "        return self.data[attribute]\n",
    "    \n",
    "    def __open_file(self):\n",
    "        self.csv_file = open(self.file_name+\".csv\",\"w+\")\n",
    "        self.writer = csv.writer(self.csv_file)        \n",
    "        self.writer.writerow(self.head)\n",
    "\n",
    "    def write_file(self):\n",
    "        \n",
    "        self.__clac_data()\n",
    "        \n",
    "        row = tuple(self.data[d.value] for d in Data)\n",
    "        \n",
    "        self.writer.writerow(row)\n",
    "    \n",
    "    def close_file(self):\n",
    "        self.csv_file.close()\n",
    "        csv = pd.read_csv(self.file_name+\".csv\", encoding='utf-8')\n",
    "        \n",
    "        #debug excel\n",
    "        csv.to_excel(self.file_name+\"_debug.xlsx\", sheet_name='data')\n",
    "        \n",
    "        #realse excel\n",
    "        relase_column = list(self.head)\n",
    "        relase_column.remove(Data.areaA.value)\n",
    "        relase_column.remove(Data.areaB.value)\n",
    "        relase_column.remove(Data.bid_id.value)\n",
    "        relase_column.remove(Data.status.value)\n",
    "        relase_column.remove(Data.consult_price.value)\n",
    "        relase_column.remove(Data.market_price.value)\n",
    "        \n",
    "        csv.to_excel(self.file_name+\"_release.xlsx\", sheet_name='data',columns =relase_column )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SfSpider:\n",
    "    \n",
    "    \n",
    "    def __init__(self,debug,debug_pages,debug_items,head_less,url,file_name):\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.debug_pages = debug_pages\n",
    "        self.debug_items = debug_items\n",
    "        self.url = url\n",
    "\n",
    "        \n",
    "        \n",
    "        self.data = DataManagement(file_name)\n",
    "        \n",
    "        if(head_less):\n",
    "            #set headless\n",
    "            chrome_options=Options()\n",
    "            chrome_options.add_argument('--headless')\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        else:\n",
    "            self.driver = webdriver.Chrome()\n",
    "            \n",
    "\n",
    "        # Setup wait for later\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "        \n",
    "    def __wait_and_click(self,mode,value,sleep_time):\n",
    "    #  Sometimes click fails unreasonably. So tries to click at all cost.\n",
    "        try:\n",
    "            if(mode == \"LINK_TEXT\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.LINK_TEXT, value)))\n",
    "            elif(mode == \"CSS_SELECTOR\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,value)))\n",
    "            elif(mode == \"XPATH\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.XPATH,value)))\n",
    "            else:\n",
    "                print('wait_and_click() error...')\n",
    "                \n",
    "            elem.click()\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            print('Click time out - {}'.format(value))\n",
    "            print('Refreshing browser...')\n",
    "            self.driver.refresh()\n",
    "            time.sleep(2)\n",
    "            return self.__wait_and_click(mode,value,sleep_time)\n",
    "\n",
    "        return elem\n",
    "        \n",
    "        \n",
    "    def do_crawling(self):\n",
    "        \n",
    "        self.driver.get(self.url)\n",
    "        \n",
    "        assert len(self.driver.window_handles) == 1\n",
    "\n",
    "        elem = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"page-total\")))\n",
    "        \n",
    "        if(self.debug):\n",
    "            pages = self.debug_pages\n",
    "        else:\n",
    "            pages = int(self.driver.find_element_by_class_name(\"page-total\").text)\n",
    "                    \n",
    "        for page in range(1,pages+1):\n",
    "            self.__do_page_crawling(page)\n",
    "\n",
    "        self.driver.quit()\n",
    "        self.data.close_file()\n",
    "        \n",
    "        \n",
    "\n",
    "    def __do_page_crawling(self,page):\n",
    "        if(page > 1):\n",
    "            self.__wait_and_click(\"LINK_TEXT\",str(page),1)\n",
    "\n",
    "        self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sf-pai-item-list\")))\n",
    "        jsonData =  json.loads(self.driver.find_element_by_id(\"sf-item-list-data\").get_attribute('innerHTML'))\n",
    "        page_data = jsonData[\"data\"]\n",
    "\n",
    "        if(self.debug):\n",
    "            items = self.debug_items\n",
    "        else:\n",
    "            items = len(page_data)    \n",
    "\n",
    "        for item in range(items):\n",
    "            item_data = page_data[item]\n",
    "            log(page,item,item_data[\"status\"])\n",
    "            \n",
    "            self.data.set_data(Data.bid_id.value,item_data[Data.bid_id.value])\n",
    "            self.data.set_data(Data.status.value,item_data[Data.status.value])\n",
    "            self.data.set_data(Data.start.value,item_data[Data.start.value])\n",
    "            self.data.set_data(Data.end.value,item_data[Data.end.value])\n",
    "            self.data.set_data(Data.title.value,item_data[Data.title.value])\n",
    "            self.data.set_data(Data.consult_price.value,item_data[Data.consult_price.value])\n",
    "            self.data.set_data(Data.market_price.value,item_data[Data.market_price.value])\n",
    "            self.data.set_data(Data.current_price.value,item_data[Data.current_price.value])            \n",
    "            self.data.set_data(Data.bid_count.value,item_data[Data.bid_count.value])\n",
    "            self.data.set_data(Data.delay_count.value,item_data[Data.delay_count.value])\n",
    "            self.data.set_data(Data.apply_count.value,item_data[Data.apply_count.value])\n",
    "            self.data.set_data(Data.item_url.value,item_data[Data.item_url.value])\n",
    "\n",
    "\n",
    "            self.__do_item_crawling(page,item)\n",
    "\n",
    "\n",
    "    def __do_item_crawling(self,page_id,item_id):\n",
    "\n",
    "        self.__wait_and_click(\"CSS_SELECTOR\",\"#pai-item-\"+str(self.data.get_data(Data.bid_id.value)),1)\n",
    "\n",
    "        # Wait for the new window or tab\n",
    "        self.wait.until(EC.number_of_windows_to_be(2))\n",
    "        handles = self.driver.window_handles\n",
    "        self.driver.switch_to.window(handles[1])\n",
    "\n",
    "       # bid times\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, \"/html[1]/body[1]/div[3]/div[4]/div[1]/div[1]/h1[1]\")))\n",
    "        self.data.set_data(Data.times.value,self.driver.find_element_by_xpath(\"/html[1]/body[1]/div[3]/div[4]/div[1]/div[1]/h1[1]\").get_attribute('textContent'))\n",
    "        #TODO: degfine new field\n",
    "\n",
    "       # 变卖公告，竞买公告\n",
    "        self.__wait_and_click(\"CSS_SELECTOR\",\"#J_DetailTabMenu > li.current.first > a\",0.5)\n",
    "\n",
    "        self.data.set_data(Data.areaA.value,self.driver.find_element_by_id(\"J_NoticeDetail\").get_attribute('textContent'))\n",
    "\n",
    "\n",
    "        self.__wait_and_click(\"LINK_TEXT\",\"标的物介绍\",0.5)\n",
    "\n",
    "        self.data.set_data(Data.areaB.value,self.driver.find_element_by_id(\"J_desc\").get_attribute('textContent'))\n",
    "\n",
    "\n",
    "        if(self.data.get_data(Data.status.value) == \"done\"):\n",
    "\n",
    "            self.__wait_and_click(\"LINK_TEXT\",\"竞价成功确认书\",0.5)\n",
    "\n",
    "            self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"content-wrap\")))\n",
    "\n",
    "            name = self.driver.find_element_by_class_name(\"c-content\").text\n",
    "        elif(self.data.get_data(Data.status.value) == \"failure\"):\n",
    "            name = \"用户姓名流拍通过\"\n",
    "        else:\n",
    "            name = \"用户姓名即将开始通过\"\n",
    "        self.data.set_data(Data.name.value,name)\n",
    "\n",
    "        self.data.write_file()\n",
    "        self.driver.close()\n",
    "        self.driver.switch_to.window(handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 2019-07-12 08:11:10.760870\n",
      "page id: 1, item id: 0, status:done\n",
      "page id: 1, item id: 1, status:done\n",
      "page id: 1, item id: 2, status:done\n",
      "page id: 1, item id: 3, status:failure\n",
      "page id: 1, item id: 4, status:failure\n",
      "page id: 1, item id: 5, status:failure\n",
      "page id: 1, item id: 6, status:failure\n",
      "page id: 1, item id: 7, status:failure\n",
      "page id: 1, item id: 8, status:failure\n",
      "page id: 1, item id: 9, status:failure\n",
      "end : 2019-07-12 08:11:45.855429\n",
      "duration: 0:00:35.094559\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    print(\"start : {0}\".format(start))\n",
    "    \n",
    "    sf = SfSpider(G_Debug,G_Debug_Pages,G_Debug_Items,G_Chrome_Hide,sourceUrl,G_FILE_NAME)\n",
    "    \n",
    "    sf.do_crawling()\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print(\"end : {0}\".format(end))\n",
    "    print(\"duration: {0}\".format(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
