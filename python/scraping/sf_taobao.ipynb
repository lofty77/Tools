{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import datetime\n",
    "from enum import Enum, unique\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_Debug = False   # if debug mode.  Debug = True. if Release mode, Debug = False.\n",
    "G_Chrome_Hide = False\n",
    "G_Debug_Pages = 2\n",
    "G_Debug_Items = 2\n",
    "\n",
    "G_FILE_NAME = 'tianjin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will bid\n",
    "# sourceUrl = (\"https://sf.taobao.com/item_list.htm?spm=a213w.7398504.filter.60.53db26cdCGMLqt&category=50025969\"  \n",
    "#                    \"&auction_source=0&province=%CC%EC%BD%F2&sorder=1&st_param=-1&auction_start_seg=-1\")\n",
    "# #done bid\n",
    "# sourceUrl = (\"https://sf.taobao.com/item_list.htm?spm=a213w.7398504.filter.26.294826cdrtlKJJ&category=50025969&auction_source=0\"\n",
    "#              \"&city=&province=%CC%EC%BD%F2&sorder=2&st_param=-1&auction_start_seg=-1\")\n",
    "\n",
    "sourceUrl = (\"https://sf.taobao.com/item_list.htm?category=50025969&auction_source=0&province=%CC%EC%BD%F2&sorder=2\"\n",
    " \"&st_param=-1&auction_start_seg=&auction_start_from=2017-02-01&auction_start_to=2017-02-20&&spm=a213w.3064813.9001.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(page_id,item_id,status,start):\n",
    "    end = datetime.datetime.now()\n",
    "    print(\"page id: {0}, item id: {1}, status:{2}, duration:{3}\".format(page_id,item_id,status,end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@unique\n",
    "class Data(Enum):\n",
    "\n",
    "    #release\n",
    "    name = \"中标人\"\n",
    "    year = \"年份\"\n",
    "    month = \"月份\"\n",
    "    start_time = \"拍卖开始\"\n",
    "    end_time = \"拍卖结束\"\n",
    "    times = \"拍卖次数\"\n",
    "    title = \"房屋地址\"\n",
    "    district = \"区域\"\n",
    "    loadStatus = \"贷款\"\n",
    "    originPrice = \"市场评估价(万)\"\n",
    "    currentPrice = \"当前价(万)\"\n",
    "    area = \"建筑面积(平方米)\"\n",
    "    discount = \"折扣(当前价/市场评估价)\"\n",
    "    unit = \"单价(万)\"\n",
    "    bidCount = \"举牌次数\"\n",
    "    delayCount = \"举牌延迟次数\"\n",
    "    applyCount = \"报名人数\"    \n",
    "    itemUrl = \"网页链接\"\n",
    "    \n",
    "    #debug\n",
    "    areaA = \"候选面积1(平方米)\"\n",
    "    areaB = \"后面面积2(平方米)\"\n",
    "    id = \"拍品编号\"\n",
    "    status = \"拍卖状态\"\n",
    "    consultPrice = \"评估价(元)\"\n",
    "    marketPrice = \"市场价(元)\"\n",
    "    supportLoans = \"普通贷款\"\n",
    "    supportOrgLoan = \"法服贷款\"\n",
    "    start = \"拍卖开始时间戳\"\n",
    "    end = \"拍卖结束时间戳\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManagement:\n",
    "    def __init__(self,file_name):\n",
    "        self.data = {}\n",
    "\n",
    "        self.file_name = file_name\n",
    "    \n",
    "        self.head = []\n",
    "        for data in Data:\n",
    "            self.head.append(data.value)\n",
    "        \n",
    "        self.__open_file()\n",
    "\n",
    "    def __process_attri_name(self,attribute, data):\n",
    "        index = data.find(\"通过\")\n",
    "        data = data[4:index]\n",
    "        self.data[attribute] =  data     \n",
    "            \n",
    "    def __process_attri_area(self,attribute, data):\n",
    "        left = data.find(\"建筑面积\")\n",
    "        if(left != -1):\n",
    "            size = data[(left+4) : (left+22)]\n",
    "            areas = re.findall(r\"\\d+\\.\\d*\",size)\n",
    "            self.data[attribute] = areas[0] if areas else 0\n",
    "        else:\n",
    "            self.data[attribute] = 0\n",
    "        \n",
    "\n",
    "        \n",
    "    def __process_attri_times(self,attribute, data):\n",
    "        keyword_postion = data.find(\"卖\")\n",
    "        if(keyword_postion != -1):\n",
    "            data = data[1:keyword_postion+1]\n",
    "        else:\n",
    "            data = \"no content\"\n",
    "            \n",
    "        self.data[attribute] = data\n",
    "\n",
    "\n",
    "\n",
    "    def __process_attri_common(self,attribute, data):\n",
    "        self.data[attribute] =  data        \n",
    "     \n",
    "    def __process_attri_url(self,attribute, data):\n",
    "        url = \"https:\"+data\n",
    "        self.data[attribute] =  url        \n",
    "\n",
    "    \n",
    "    def __clac_data(self):\n",
    "        # \n",
    "        if (int(self.data[Data.consultPrice.name]) > 0):\n",
    "            originPrice = self.data[Data.consultPrice.name]\n",
    "        else:\n",
    "            originPrice = self.data[Data.marketPrice.name]\n",
    "        #\n",
    "        if (int(originPrice)  == 0):\n",
    "            self.data[Data.discount.name] = \"error\"\n",
    "        else:\n",
    "            self.data[Data.discount.name]  = float(\"%.2f\" % float(int(self.data[Data.currentPrice.name])/originPrice))\n",
    " \n",
    "       # change unit to from RMB yuan to  RMB Wan\n",
    "        self.data[Data.originPrice.name]  = float(\"%.2f\" % float(int(originPrice)/10000))        \n",
    "        self.data[Data.currentPrice.name] = float(\"%.2f\" % float(int(self.data[Data.currentPrice.name])/10000))\n",
    "\n",
    "      # set area\n",
    "        if(float(self.data[Data.areaA.name]) > 0):\n",
    "            self.data[Data.area.name]  = self.data[Data.areaA.name]\n",
    "            self.data[Data.unit.name] = float(\"%.2f\" % float(int(self.data[Data.currentPrice.name])/float(self.data[Data.area.name]) ))\n",
    "        elif(float(self.data[Data.areaB.name]) > 0):\n",
    "            self.data[Data.area.name] = self.data[Data.areaB.name]\n",
    "            self.data[Data.unit.name] = float(\"%.2f\" % float(int(self.data[Data.currentPrice.name])/float(self.data[Data.area.name]) ))\n",
    "        else:\n",
    "            self.data[Data.area.name] = 0\n",
    "            self.data[Data.unit.name] = 0\n",
    "        \n",
    "        ## start_time, end_time\n",
    "        start = int(int(self.data[Data.start.name])/1000 )\n",
    "        self.data[Data.start_time.name] = str(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(start)))\n",
    "        \n",
    "        end = int(int(self.data[Data.end.name])/1000 )\n",
    "        self.data[Data.end_time.name] = str(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(end)))\n",
    "        \n",
    "        ## set year, month\n",
    "        date_start = self.data[Data.start_time.name]\n",
    "        data_split = date_start.split(\"-\",2)\n",
    "        self.data[Data.year.name] = data_split[0]\n",
    "        self.data[Data.month.name] = data_split[1]\n",
    "        ## set load\n",
    "        if int(self.data[Data.supportLoans.name]) == 0 and int(self.data[Data.supportOrgLoan.name]) == 0:\n",
    "            self.data[Data.loadStatus.name] = \"不支持\"\n",
    "        elif int(self.data[Data.supportLoans.name]) == 1 and int(self.data[Data.supportOrgLoan.name]) == 1:\n",
    "            self.data[Data.loadStatus.name] = \"支持(法服&普通)\"\n",
    "        elif int(self.data[Data.supportOrgLoan.name]) == 1:\n",
    "            self.data[Data.loadStatus.name] = \"支持(法服)\"\n",
    "        else:\n",
    "            self.data[Data.loadStatus.name] = \"支持(普通)\"\n",
    "\n",
    "        ## district\n",
    "        address = self.data[Data.title.name]\n",
    "        city_pos = address.find(\"市\")\n",
    "        district_pos = address.find(\"区\")\n",
    "\n",
    "        if city_pos > 0 and district_pos > 0:\n",
    "            self.data[Data.district.name] = address[city_pos+1:district_pos+1]\n",
    "        elif city_pos == -1 and district_pos > 0:\n",
    "            city_pos = address.find(\"天津\")\n",
    "            if city_pos > -1 :\n",
    "                self.data[Data.district.name] = address[city_pos+2:district_pos+1]\n",
    "            else:\n",
    "                self.data[Data.district.name] = address[0:district_pos+1]\n",
    "        else:\n",
    "            self.data[Data.district.name] = \"未知区\"\n",
    "        ###\n",
    "\n",
    "        \n",
    "    \n",
    "    def set_data(self,attribute, data):\n",
    "        if(attribute == Data.name.name):\n",
    "            self.__process_attri_name(attribute, data)\n",
    "        elif(attribute == Data.areaA.name or attribute == Data.areaB.name):\n",
    "            self.__process_attri_area(attribute, data)\n",
    "        elif(attribute == Data.times.name):\n",
    "            self.__process_attri_times(attribute, data)\n",
    "        elif(attribute == Data.itemUrl.name):\n",
    "            self.__process_attri_url(attribute, data)\n",
    "        else:\n",
    "            self.__process_attri_common(attribute,data)    \n",
    "    \n",
    "    \n",
    "    def get_data(self,attribute):\n",
    "        return self.data[attribute]\n",
    "    \n",
    "    def __open_file(self):\n",
    "        self.csv_file = open(self.file_name+\".csv\",\"w+\")\n",
    "        self.writer = csv.writer(self.csv_file)        \n",
    "        self.writer.writerow(self.head)\n",
    "\n",
    "    def write_file(self):\n",
    "        \n",
    "        self.__clac_data()\n",
    "        \n",
    "        row = tuple(self.data[d.name] for d in Data)\n",
    "        \n",
    "        self.writer.writerow(row)\n",
    "    \n",
    "    def close_file(self):\n",
    "        self.csv_file.close()\n",
    "        csv = pd.read_csv(self.file_name+\".csv\", encoding='utf-8')\n",
    "        \n",
    "        #debug excel\n",
    "        csv.to_excel(self.file_name+\"_debug.xlsx\", sheet_name='data')\n",
    "        \n",
    "        #realse excel\n",
    "        relase_column = list(self.head)\n",
    "        relase_column.remove(Data.areaA.value)\n",
    "        relase_column.remove(Data.areaB.value)\n",
    "        relase_column.remove(Data.id.value)\n",
    "        relase_column.remove(Data.status.value)\n",
    "        relase_column.remove(Data.consultPrice.value)\n",
    "        relase_column.remove(Data.marketPrice.value)\n",
    "        relase_column.remove(Data.supportLoans.value)\n",
    "        relase_column.remove(Data.supportOrgLoan.value)\n",
    "        relase_column.remove(Data.start.value)\n",
    "        relase_column.remove(Data.end.value)\n",
    "        \n",
    "        csv.to_excel(self.file_name+\"_release.xlsx\", sheet_name='data',columns =relase_column )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SfSpider:\n",
    "    \n",
    "    \n",
    "    def __init__(self,debug,debug_pages,debug_items,head_less,url,file_name):\n",
    "        \n",
    "        self.debug = debug\n",
    "        self.debug_pages = debug_pages\n",
    "        self.debug_items = debug_items\n",
    "        self.url = url\n",
    "        self.refresh_count = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        self.data = DataManagement(file_name)\n",
    "        \n",
    "        if(head_less):\n",
    "            #set headless\n",
    "            chrome_options=Options()\n",
    "            chrome_options.add_argument('--headless')\n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "        else:\n",
    "            self.driver = webdriver.Chrome()\n",
    "            \n",
    "\n",
    "        # Setup wait for later\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "        \n",
    "    def __wait_and_click(self,mode,value,sleep_time):\n",
    "    #  Sometimes click fails unreasonably. So tries to click at all cost.\n",
    "        try:\n",
    "            if(mode == \"LINK_TEXT\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.LINK_TEXT, value)))\n",
    "            elif(mode == \"CSS_SELECTOR\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR,value)))\n",
    "            elif(mode == \"XPATH\"):\n",
    "                elem = self.wait.until(EC.element_to_be_clickable((By.XPATH,value)))\n",
    "            else:\n",
    "                print('wait_and_click() error...')\n",
    "                \n",
    "            elem.click()\n",
    "            time.sleep(sleep_time)\n",
    "        except Exception as e:\n",
    "            print('Click time out - {}'.format(value))\n",
    "            if(self.refresh_count < 1):\n",
    "                self.refresh_count += 1\n",
    "                print('Refreshing browser...')\n",
    "                self.driver.refresh()\n",
    "                time.sleep(2)\n",
    "                return self.__wait_and_click(mode,value,sleep_time)\n",
    "            else:\n",
    "                print('more than MAX refresh count..')\n",
    "                self.refresh_count = 0\n",
    "                return False\n",
    "   \n",
    "        self.refresh_count = 0\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def do_crawling(self):\n",
    "        \n",
    "        self.driver.get(self.url)\n",
    "        \n",
    "        assert len(self.driver.window_handles) == 1\n",
    "\n",
    "        elem = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"page-total\")))\n",
    "        \n",
    "        if(self.debug):\n",
    "            pages = self.debug_pages\n",
    "        else:\n",
    "            pages = int(self.driver.find_element_by_class_name(\"page-total\").text)\n",
    "                    \n",
    "        for page in range(1,pages+1):\n",
    "            self.__do_page_crawling(page)\n",
    "\n",
    "        self.driver.quit()\n",
    "        self.data.close_file()\n",
    "        \n",
    "        \n",
    "\n",
    "    def __do_page_crawling(self,page):\n",
    "        if(page > 1):\n",
    "            self.__wait_and_click(\"LINK_TEXT\",str(page),1)\n",
    "\n",
    "        self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"sf-pai-item-list\")))\n",
    "        jsonData =  json.loads(self.driver.find_element_by_id(\"sf-item-list-data\").get_attribute('innerHTML'))\n",
    "        page_data = jsonData[\"data\"]\n",
    "\n",
    "        if(self.debug):\n",
    "            items = self.debug_items\n",
    "        else:\n",
    "            items = len(page_data)    \n",
    "\n",
    "        for item in range(items):\n",
    "            item_data = page_data[item]\n",
    "            \n",
    "            start = datetime.datetime.now()  \n",
    "            \n",
    "            self.data.set_data(Data.id.name,item_data[Data.id.name])\n",
    "            self.data.set_data(Data.status.name,item_data[Data.status.name])\n",
    "            self.data.set_data(Data.start.name,item_data[Data.start.name])\n",
    "            self.data.set_data(Data.end.name,item_data[Data.end.name])\n",
    "            self.data.set_data(Data.title.name,item_data[Data.title.name])\n",
    "            self.data.set_data(Data.consultPrice.name,item_data[Data.consultPrice.name])\n",
    "            self.data.set_data(Data.marketPrice.name,item_data[Data.marketPrice.name])\n",
    "            self.data.set_data(Data.currentPrice.name,item_data[Data.currentPrice.name])            \n",
    "            self.data.set_data(Data.bidCount.name,item_data[Data.bidCount.name])\n",
    "            self.data.set_data(Data.delayCount.name,item_data[Data.delayCount.name])\n",
    "            self.data.set_data(Data.applyCount.name,item_data[Data.applyCount.name])\n",
    "            self.data.set_data(Data.itemUrl.name,item_data[Data.itemUrl.name])\n",
    "            self.data.set_data(Data.supportLoans.name,item_data[Data.supportLoans.name])\n",
    "            self.data.set_data(Data.supportOrgLoan.name,item_data[Data.supportOrgLoan.name])\n",
    "\n",
    "            self.__do_item_crawling(page,item)\n",
    "\n",
    "            log(page,item,item_data[\"status\"],start)\n",
    "\n",
    "\n",
    "\n",
    "    def __do_item_crawling(self,page_id,item_id):\n",
    "\n",
    "        self.__wait_and_click(\"CSS_SELECTOR\",\"#pai-item-\"+str(self.data.get_data(Data.id.name)),1)\n",
    "\n",
    "        # Wait for the new window or tab\n",
    "        self.wait.until(EC.number_of_windows_to_be(2))\n",
    "        handles = self.driver.window_handles\n",
    "        self.driver.switch_to.window(handles[1])\n",
    "\n",
    "       # bid times\n",
    "        self.wait.until(EC.presence_of_element_located((By.XPATH, \"/html[1]/body[1]/div[3]/div[4]/div[1]/div[1]/h1[1]\")))\n",
    "        self.data.set_data(Data.times.name,self.driver.find_element_by_xpath(\"/html[1]/body[1]/div[3]/div[4]/div[1]/div[1]/h1[1]\").get_attribute('textContent'))\n",
    "        #TODO: degfine new field\n",
    "\n",
    "       # 变卖公告，竞买公告\n",
    "        self.__wait_and_click(\"CSS_SELECTOR\",\"#J_DetailTabMenu > li.current.first > a\",0.5)\n",
    "\n",
    "        self.data.set_data(Data.areaA.name,self.driver.find_element_by_id(\"J_NoticeDetail\").get_attribute('textContent'))\n",
    "\n",
    "\n",
    "        self.__wait_and_click(\"LINK_TEXT\",\"标的物介绍\",0.5)\n",
    "\n",
    "        self.data.set_data(Data.areaB.name,self.driver.find_element_by_id(\"J_desc\").get_attribute('textContent'))\n",
    "\n",
    "        if(self.data.get_data(Data.status.name) == \"done\"):\n",
    "            \n",
    "            if self.data.get_data(Data.start.name) > 1486432800000:   # 2017-2-7\n",
    "                if self.__wait_and_click(\"LINK_TEXT\",\"竞价成功确认书\",0.5):\n",
    "                    self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"content-wrap\")))\n",
    "                    name = self.driver.find_element_by_class_name(\"c-content\").text\n",
    "                else:\n",
    "                    name = \"用户姓名无名氏通过\"\n",
    "            else:\n",
    "                    name = \"用户姓名无名氏通过\"\n",
    "        elif(self.data.get_data(Data.status.name) == \"failure\"):\n",
    "            name = \"用户姓名流拍通过\"\n",
    "        else:\n",
    "            name = \"用户姓名即将开始通过\"\n",
    "        self.data.set_data(Data.name.name,name)\n",
    "\n",
    "        self.data.write_file()\n",
    "        self.driver.close()\n",
    "        self.driver.switch_to.window(handles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start : 2019-08-05 08:14:39.808983\n",
      "page id: 1, item id: 0, status:done, duration:0:00:03.728449\n",
      "page id: 1, item id: 1, status:done, duration:0:00:03.426178\n",
      "page id: 1, item id: 2, status:failure, duration:0:00:02.709665\n",
      "page id: 1, item id: 3, status:done, duration:0:00:04.283551\n",
      "page id: 1, item id: 4, status:done, duration:0:00:03.433722\n",
      "page id: 1, item id: 5, status:failure, duration:0:00:02.747790\n",
      "page id: 1, item id: 6, status:failure, duration:0:00:03.043890\n",
      "page id: 1, item id: 7, status:failure, duration:0:00:03.387019\n",
      "page id: 1, item id: 8, status:failure, duration:0:00:03.009658\n",
      "page id: 1, item id: 9, status:done, duration:0:00:03.881594\n",
      "page id: 1, item id: 10, status:done, duration:0:00:03.961639\n",
      "page id: 1, item id: 11, status:failure, duration:0:00:03.090332\n",
      "page id: 1, item id: 12, status:failure, duration:0:00:02.976328\n",
      "page id: 1, item id: 13, status:failure, duration:0:00:02.770284\n",
      "page id: 1, item id: 14, status:failure, duration:0:00:02.731867\n",
      "page id: 1, item id: 15, status:failure, duration:0:00:02.843240\n",
      "page id: 1, item id: 16, status:failure, duration:0:00:02.657972\n",
      "page id: 1, item id: 17, status:failure, duration:0:00:02.752288\n",
      "page id: 1, item id: 18, status:failure, duration:0:00:02.765398\n",
      "page id: 1, item id: 19, status:failure, duration:0:00:02.798150\n",
      "Click time out - 竞价成功确认书\n",
      "Refreshing browser...\n",
      "Click time out - 竞价成功确认书\n",
      "more than MAX refresh count..\n",
      "page id: 1, item id: 20, status:done, duration:0:00:25.292117\n",
      "page id: 1, item id: 21, status:failure, duration:0:00:02.782909\n",
      "page id: 1, item id: 22, status:failure, duration:0:00:02.753005\n",
      "page id: 1, item id: 23, status:failure, duration:0:00:02.770922\n",
      "page id: 1, item id: 24, status:failure, duration:0:00:02.787055\n",
      "page id: 1, item id: 25, status:done, duration:0:00:03.465217\n",
      "page id: 1, item id: 26, status:done, duration:0:00:03.493211\n",
      "page id: 1, item id: 27, status:failure, duration:0:00:02.796492\n",
      "page id: 1, item id: 28, status:failure, duration:0:00:02.800037\n",
      "page id: 1, item id: 29, status:failure, duration:0:00:03.477391\n",
      "page id: 1, item id: 30, status:failure, duration:0:00:03.305921\n",
      "page id: 2, item id: 0, status:failure, duration:0:00:02.718461\n",
      "page id: 2, item id: 1, status:failure, duration:0:00:02.811437\n",
      "page id: 2, item id: 2, status:done, duration:0:00:04.072225\n",
      "page id: 2, item id: 3, status:done, duration:0:00:03.836661\n",
      "page id: 2, item id: 4, status:failure, duration:0:00:02.785191\n",
      "page id: 2, item id: 5, status:failure, duration:0:00:02.763419\n",
      "page id: 2, item id: 6, status:done, duration:0:00:03.479889\n",
      "page id: 2, item id: 7, status:failure, duration:0:00:02.776134\n",
      "page id: 2, item id: 8, status:done, duration:0:00:03.439164\n",
      "page id: 2, item id: 9, status:done, duration:0:00:02.755633\n",
      "page id: 2, item id: 10, status:done, duration:0:00:02.747221\n",
      "page id: 2, item id: 11, status:done, duration:0:00:02.736660\n",
      "page id: 2, item id: 12, status:done, duration:0:00:02.790288\n",
      "page id: 2, item id: 13, status:done, duration:0:00:02.864705\n",
      "page id: 2, item id: 14, status:done, duration:0:00:02.776420\n",
      "page id: 2, item id: 15, status:done, duration:0:00:02.817219\n",
      "page id: 2, item id: 16, status:failure, duration:0:00:02.716000\n",
      "page id: 2, item id: 17, status:done, duration:0:00:02.763298\n",
      "page id: 2, item id: 18, status:done, duration:0:00:02.779782\n",
      "page id: 2, item id: 19, status:failure, duration:0:00:02.762860\n",
      "page id: 2, item id: 20, status:failure, duration:0:00:02.826462\n",
      "page id: 2, item id: 21, status:done, duration:0:00:02.676577\n",
      "page id: 2, item id: 22, status:done, duration:0:00:02.807040\n",
      "page id: 2, item id: 23, status:done, duration:0:00:02.780789\n",
      "page id: 2, item id: 24, status:done, duration:0:00:02.867296\n",
      "page id: 2, item id: 25, status:failure, duration:0:00:02.772472\n",
      "page id: 2, item id: 26, status:failure, duration:0:00:02.660704\n",
      "page id: 2, item id: 27, status:failure, duration:0:00:02.751140\n",
      "page id: 2, item id: 28, status:done, duration:0:00:02.793366\n",
      "end : 2019-08-05 08:18:11.413249\n",
      "duration: 0:03:31.604266\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    print(\"start : {0}\".format(start))\n",
    "    \n",
    "    sf = SfSpider(G_Debug,G_Debug_Pages,G_Debug_Items,G_Chrome_Hide,sourceUrl,G_FILE_NAME)\n",
    "    \n",
    "    sf.do_crawling()\n",
    "    \n",
    "    end = datetime.datetime.now()\n",
    "    print(\"end : {0}\".format(end))\n",
    "    print(\"duration: {0}\".format(end-start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
